{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action output Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data from walkthrough to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from jericho import *\n",
    "\n",
    "env = FrotzEnv(\"../../../z-machine-games-master/jericho-game-suite/zork1.z5\")\n",
    "initial_observation, info = env.reset()\n",
    "walkthrough = env.get_walkthrough()\n",
    "with open('raw/zork1_z5_walkthrough.jsonl', 'w', encoding='utf-8') as f:\n",
    "    initial_data = {\n",
    "        \"observation\": initial_observation,\n",
    "        \"inventory\": env.get_inventory(),\n",
    "        \"candidates\": env.get_valid_actions(),\n",
    "        \"gold_action\": walkthrough[0]\n",
    "    }\n",
    "    f.write(json.dumps(initial_data) + '\\n')  # Convert to JSON string and add newline\n",
    "    \n",
    "    for step, act in enumerate(walkthrough):\n",
    "        return_ = env.step(act)\n",
    "        print(return_)\n",
    "        data = {\n",
    "            \"observation\": return_[0],\n",
    "            \"inventory\": [item.name for item in env.get_inventory()],\n",
    "            \"candidate\": env.get_valid_actions(),\n",
    "            \"gold_action\": walkthrough[step+1]\n",
    "        }\n",
    "        f.write(json.dumps(data) + '\\n')  # Convert to JSON string and add newline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer to LoRA format dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are playing the interactive fiction game Zork.\\n\"\n",
    "    \"Your goal is to explore the world, collect treasures, solve puzzles, and maximize your score.\\n\"\n",
    "    \"You interact with the world by typing commands like \\\"go north\\\", \\\"open door\\\", \\\"take lamp\\\", etc.\\n\"\n",
    "    \"You see the world through textual descriptions (observations), and your inventory tells you what you're carrying.\\n\"\n",
    "    \"At each step, you will be shown some candidate actions for reference.\\n\"\n",
    "    \"You can either choose one of them, or generate your own appropriate action to proceed.\\n\\n\"\n",
    ")\n",
    "\n",
    "class ZorkSFTDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer=None, max_history=3, max_length=1024):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_history = max_history\n",
    "        self.max_length = max_length\n",
    "        self.data = self.build_from_walkthrough(path)\n",
    "\n",
    "    def build_from_walkthrough(self, path):\n",
    "        with open(path, \"r\") as f:\n",
    "            lines = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "        samples = []\n",
    "        for i in range(1, len(lines)-1):\n",
    "            history = lines[max(0, i - self.max_history):i]\n",
    "            sample = {\n",
    "                \"history\": history,\n",
    "                \"observation\": lines[i][\"observation\"],\n",
    "                \"inventory\": lines[i][\"inventory\"],\n",
    "                \"candidates\": lines[i][\"candidates\"], \n",
    "                \"gold_action\": lines[i][\"gold_action\"]\n",
    "            }\n",
    "            samples.append(sample)\n",
    "        return samples\n",
    "\n",
    "    def build_prompt(self, item):\n",
    "        prompt = SYSTEM_PROMPT\n",
    "\n",
    "        if item.get(\"history\"):\n",
    "            prompt += \"--- Previous Actions & Observations ---\\n\"\n",
    "            for step in item[\"history\"]:\n",
    "                prompt += f\"{step['observation'].strip()} \\n>{step['gold_action'].strip()}\\n\"\n",
    "            prompt += \"\\n\"\n",
    "\n",
    "        prompt += \"--- Current Observation ---\\n\"\n",
    "        prompt += f\"Observation: {item['observation']}\\n\"\n",
    "        prompt += f\"Inventory: {item['inventory']}\\n\"\n",
    "\n",
    "        if item[\"candidates\"]:\n",
    "            prompt += \"Choices:\\n\"\n",
    "            for i, choice in enumerate(item[\"candidates\"], 1):\n",
    "                prompt += f\"({i}) {choice}\\n\"\n",
    "        prompt += \"\\nWhat should you do next?\\nAnswer:\"\n",
    "        return prompt\n",
    "\n",
    "    def to_jsonl(self, output_path):\n",
    "        with open(output_path, \"w\") as f:\n",
    "            for item in self.data:\n",
    "                context = self.build_prompt(item)\n",
    "                target = item[\"gold_action\"]\n",
    "                record = {\n",
    "                    \"context\": context,\n",
    "                    \"target\": target\n",
    "                }\n",
    "                f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "dataset = ZorkSFTDataset('raw/zork1_z5_walkthrough.jsonl')\n",
    "dataset.to_jsonl('raw/zork1_wt_lora.jsonl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "\n",
    "def preprocess(tokenizer, config, example, max_seq_length):\n",
    "    prompt = example[\"context\"]\n",
    "    target = example[\"target\"]\n",
    "    prompt_ids = tokenizer.encode(prompt, max_length=max_seq_length, truncation=True)\n",
    "    target_ids = tokenizer.encode(\n",
    "        target,\n",
    "        max_length=max_seq_length,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False)\n",
    "    input_ids = prompt_ids + target_ids + [config.eos_token_id]\n",
    "    return {\"input_ids\": input_ids, \"seq_len\": len(prompt_ids)}\n",
    "\n",
    "\n",
    "def read_jsonl(model_name, path, max_seq_length, skip_overlength=False):\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(f\"{model_name}\", trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    config = transformers.AutoConfig.from_pretrained(\n",
    "        f\"/data3/whr/zhk/huggingface/{model_name}\", trust_remote_code=True, device_map='auto')\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            example = json.loads(line)\n",
    "            feature = preprocess(tokenizer, config, example, max_seq_length)\n",
    "            if skip_overlength and len(feature[\"input_ids\"]) > max_seq_length:\n",
    "                continue\n",
    "            feature[\"input_ids\"] = feature[\"input_ids\"][:max_seq_length]\n",
    "            yield feature\n",
    "\n",
    "\n",
    "\n",
    "jsonl_path = \"raw/zork1_wt_lora.jsonl\"\n",
    "save_path = \"processed/\"\n",
    "max_seq_length = 1024\n",
    "model_name = \"qwen-2.5-3B-instruct\"\n",
    "skip_overlength = False\n",
    "\n",
    "print(\"#> Tokenizing dataset...\")\n",
    "print(\"#> Input path: {}\".format(jsonl_path))\n",
    "print(\"#> Output path: {}\".format(save_path))\n",
    "print(\"#> Max sequence length: {}\".format(max_seq_length))\n",
    "print(\"#> Skip overlength: {}\".format(skip_overlength))\n",
    "\n",
    "\n",
    "\n",
    "dataset = datasets.Dataset.from_generator(\n",
    "    lambda: read_jsonl(model_name, jsonl_path, max_seq_length, skip_overlength)\n",
    ")\n",
    "save_path = f'processed/{model_name}'\n",
    "dataset.save_to_disk(save_path)\n",
    "\n",
    "print(\"#> Tokenization finished!\", \"Total examples:\", len(dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are playing the interactive fiction game Zork.\\n\"\n",
    "    \"Your goal is to explore the world, collect treasures, solve puzzles, and maximize your score.\\n\"\n",
    "    \"You interact with the world by typing commands like \\\"go north\\\", \\\"open door\\\", \\\"take lamp\\\", etc.\\n\"\n",
    "    \"You see the world through textual descriptions (observations), and your inventory tells you what you're carrying.\\n\"\n",
    "    \"At each step, you will be shown some candidate actions for reference.\\n\"\n",
    "    \"You can either choose one of them, or generate your own appropriate action to proceed.\\n\\n\"\n",
    ")\n",
    "\n",
    "class ZorkSFTDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer=None, max_history=3, max_length=1024):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_history = max_history\n",
    "        self.max_length = max_length\n",
    "        self.data = self.build_from_walkthrough(path)\n",
    "\n",
    "    def build_from_walkthrough(self, path):\n",
    "        with open(path, \"r\") as f:\n",
    "            lines = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "        samples = []\n",
    "        for i in range(1, len(lines)-1):\n",
    "            history = lines[max(0, i - self.max_history):i]\n",
    "            sample = {\n",
    "                \"history\": history,\n",
    "                \"observation\": lines[i][\"observation\"],\n",
    "                \"inventory\": lines[i][\"inventory\"],\n",
    "                \"candidates\": lines[i][\"candidates\"], \n",
    "                \"gold_action\": lines[i][\"gold_action\"]\n",
    "            }\n",
    "            samples.append(sample)\n",
    "        return samples\n",
    "\n",
    "    def build_prompt(self, item):\n",
    "        prompt = SYSTEM_PROMPT\n",
    "\n",
    "        if item.get(\"history\"):\n",
    "            prompt += \"--- Previous Actions & Observations ---\\n\"\n",
    "            for step in item[\"history\"]:\n",
    "                prompt += f\"{step['observation'].strip()} \\n>{step['gold_action'].strip()}\\n\"\n",
    "            prompt += \"\\n\"\n",
    "\n",
    "        prompt += \"--- Current Observation ---\\n\"\n",
    "        prompt += f\"Observation: {item['observation']}\\n\"\n",
    "        prompt += f\"Inventory: {item['inventory']}\\n\"\n",
    "\n",
    "        if item[\"candidates\"]:\n",
    "            prompt += \"Choices:\\n\"\n",
    "            for i, choice in enumerate(item[\"candidates\"], 1):\n",
    "                prompt += f\"({i}) {choice}\\n\"\n",
    "        prompt += \"\\nWhat should you do next?\\nAnswer:\"\n",
    "        return prompt\n",
    "\n",
    "    def to_jsonl(self, output_path):\n",
    "        with open(output_path, \"w\") as f:\n",
    "            for item in self.data:\n",
    "                context = self.build_prompt(item)\n",
    "                record = {\n",
    "                    \"context\": context\n",
    "                }\n",
    "                f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "dataset = ZorkSFTDataset('raw/zork1_z5_walkthrough.jsonl')\n",
    "dataset.to_jsonl('raw/zork1_wt_inference.jsonl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from jericho import *\n",
    "\n",
    "env = FrotzEnv(\"../../../z-machine-games-master/jericho-game-suite/zork1.z5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'West House'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_player_location().name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## walkthrough data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I beg your pardon?\n",
      "\n",
      "\n",
      "West of House\n",
      "You are standing in an open field west of a white house, with a boarded front door.\n",
      "There is a small mailbox here.\n",
      "\n",
      "\n",
      "Opening the small mailbox reveals a leaflet.\n",
      "\n",
      "\n",
      "It is already open.\n",
      "\n",
      "\n",
      "(leaflet)\n",
      "(Taken)\n",
      "\"WELCOME TO ZORK!\n",
      "\n",
      "ZORK is a game of adventure, danger, and low cunning. In it you will explore some of the most amazing territory ever seen by mortals. No computer should be without one!\"\n",
      "\n",
      "\n",
      "\n",
      "You already have that!\n",
      "\n",
      "\n",
      "(leaflet)\n",
      "\"WELCOME TO ZORK!\n",
      "\n",
      "ZORK is a game of adventure, danger, and low cunning. In it you will explore some of the most amazing territory ever seen by mortals. No computer should be without one!\"\n",
      "\n",
      "\n",
      "\n",
      "North of House\n",
      "You are facing the north side of a white house. There is no door here, and all the windows are boarded up. To the north a narrow path winds through the trees.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from jericho import *\n",
    "\n",
    "env = FrotzEnv(\"../../../z-machine-games-master/jericho-game-suite/zork1.z5\")\n",
    "initial_observation, info = env.reset()\n",
    "walkthrough = env.get_walkthrough()\n",
    "\n",
    "with open('raw/zork1_z5_walkthrough_reward.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for step in range(len(walkthrough)):\n",
    "        location = env.get_player_location().name\n",
    "        inventory = [item.name for item in env.get_inventory()]\n",
    "        gold_action = walkthrough[step]\n",
    "\n",
    "        observation, reward, done, info = env.step(gold_action)\n",
    "\n",
    "        data = {\n",
    "            \"location\": location,\n",
    "            \"inventory\": inventory,\n",
    "            \"gold_action\": gold_action,\n",
    "            \"reward\": reward\n",
    "        }\n",
    "        f.write(json.dumps(data) + '\\n')\n",
    "\n",
    "        if done:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a reward model trained to evaluate the quality of actions taken in the game Zork.\\n\"\n",
    "    \"You are given the player's current location, their inventory, and the action they just performed.\\n\"\n",
    "    \"Your task is to score how beneficial the action is on a scale from 0 to 1, where:\\n\"\n",
    "    \"- 0 means the action is useless or redundant\\n\"\n",
    "    \"- 1 means the action is extremely valuable for game progression\\n\\n\"\n",
    "    \"You should reward actions that:\\n\"\n",
    "    \"- Collect or use key items (e.g., lamp, keys)\\n\"\n",
    "    \"- Explore new areas\\n\"\n",
    "    \"- Solve puzzles (e.g., moving rug, praying at mirror)\\n\"\n",
    "    \"- Defeat enemies\\n\"\n",
    "    \"- Store treasures\\n\"\n",
    "    \"- Progress the story\\n\\n\"\n",
    "    \"You should penalty actions that:\\n\"\n",
    "    \"- Useless direction move and repeat\\n\"\n",
    ")\n",
    "\n",
    "class ZorkRMHistoryDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer=None, max_history=3, max_length=1024):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_history = max_history\n",
    "        self.max_length = max_length\n",
    "        self.data = self.build_from_walkthrough(path)\n",
    "\n",
    "    def build_from_walkthrough(self, path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "        raw_rewards = []\n",
    "        for line in lines:\n",
    "            r = line.get(\"reward\", 0)\n",
    "            raw_rewards.append(r)\n",
    "\n",
    "        min_reward = min(raw_rewards)\n",
    "        max_reward = max(raw_rewards)\n",
    "        reward_range = max_reward - min_reward if max_reward > min_reward else 1\n",
    "        print(max_reward)\n",
    "        samples = []\n",
    "        for i in range(1, len(lines)-1):\n",
    "            history = lines[max(0, i - self.max_history):i]\n",
    "            location = lines[i].get(\"location\", \"Unknown\")\n",
    "            inventory = lines[i].get(\"inventory\", [])\n",
    "            action = lines[i].get(\"gold_action\", \"\")\n",
    "            reward = lines[i].get(\"reward\", 0)\n",
    "\n",
    "            normalized_reward = (reward - min_reward) / reward_range\n",
    "\n",
    "            sample = {\n",
    "                \"history\": history,\n",
    "                \"location\": location,\n",
    "                \"inventory\": inventory,\n",
    "                \"gold_action\": action,\n",
    "                \"reward\": normalized_reward\n",
    "            }\n",
    "            samples.append(sample)\n",
    "        return samples\n",
    "\n",
    "\n",
    "    def build_prompt(self, item):\n",
    "        prompt = SYSTEM_PROMPT\n",
    "\n",
    "        if item.get(\"history\"):\n",
    "            prompt += \"--- Previous Actions & Observations ---\\n\"\n",
    "            for step in item[\"history\"]:\n",
    "                prompt += f\"location:{step['location'].strip()} \\n inventory:{step['inventory']} \\n>action:{step['gold_action'].strip()}\\n\\n\"\n",
    "            prompt += \"\\n\"\n",
    "\n",
    "        prompt += \"--- Current Observation ---\\n\"\n",
    "        prompt += f\"Location: {item['location']}\\n\"\n",
    "        prompt += f\"Inventory: {item['inventory']}\\n\"\n",
    "        prompt += f\"Action: {item['gold_action']}\\n\\n\"\n",
    "        prompt += \"Score this action from 0 to 1:\\nAnswer:\"\n",
    "        return prompt\n",
    "\n",
    "    def to_jsonl(self, output_path):\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for item in self.data:\n",
    "                context = self.build_prompt(item)\n",
    "                target = item[\"reward\"]\n",
    "                record = {\n",
    "                    \"context\": context,\n",
    "                    \"target\": str(target)\n",
    "                }\n",
    "                f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "dataset = ZorkRMHistoryDataset('raw/zork1_walkthrough_reward_relabel.jsonl')\n",
    "dataset.to_jsonl('raw/zork1_rm_lora_dataset_penalty.jsonl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Tokenizing dataset...\n",
      "#> Input path: raw/zork1_rm_lora_dataset_penalty.jsonl\n",
      "#> Output path: processed/\n",
      "#> Max sequence length: 1024\n",
      "#> Skip overlength: False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdd3a5f65174ded8e483cb891c14ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/396 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Tokenization finished! Total examples: 396\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "\n",
    "def preprocess(tokenizer, config, example, max_seq_length):\n",
    "    prompt = example[\"context\"]\n",
    "    target = example[\"target\"]\n",
    "    prompt_ids = tokenizer.encode(prompt, max_length=max_seq_length, truncation=True)\n",
    "    target_ids = tokenizer.encode(\n",
    "        target,\n",
    "        max_length=max_seq_length,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False)\n",
    "    input_ids = prompt_ids + target_ids + [config.eos_token_id]\n",
    "    return {\"input_ids\": input_ids, \"seq_len\": len(prompt_ids)}\n",
    "\n",
    "\n",
    "def read_jsonl(model_name, path, max_seq_length, skip_overlength=False):\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(f\"/data3/whr/zhk/huggingface/{model_name}\", trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    config = transformers.AutoConfig.from_pretrained(\n",
    "        f\"/data3/whr/zhk/huggingface/{model_name}\", trust_remote_code=True, device_map='auto')\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            example = json.loads(line)\n",
    "            feature = preprocess(tokenizer, config, example, max_seq_length)\n",
    "            if skip_overlength and len(feature[\"input_ids\"]) > max_seq_length:\n",
    "                continue\n",
    "            feature[\"input_ids\"] = feature[\"input_ids\"][:max_seq_length]\n",
    "            yield feature\n",
    "\n",
    "\n",
    "\n",
    "jsonl_path = \"raw/zork1_rm_lora_dataset_penalty.jsonl\"\n",
    "save_path = \"processed/\"\n",
    "max_seq_length = 1024\n",
    "model_name = \"qwen-2.5-1.5B-instruct\"\n",
    "skip_overlength = False\n",
    "\n",
    "print(\"#> Tokenizing dataset...\")\n",
    "print(\"#> Input path: {}\".format(jsonl_path))\n",
    "print(\"#> Output path: {}\".format(save_path))\n",
    "print(\"#> Max sequence length: {}\".format(max_seq_length))\n",
    "print(\"#> Skip overlength: {}\".format(skip_overlength))\n",
    "\n",
    "\n",
    "\n",
    "dataset = datasets.Dataset.from_generator(\n",
    "    lambda: read_jsonl(model_name, jsonl_path, max_seq_length, skip_overlength)\n",
    ")\n",
    "save_path = f'processed/{model_name}'\n",
    "dataset.save_to_disk(save_path)\n",
    "\n",
    "print(\"#> Tokenization finished!\", \"Total examples:\", len(dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "ACTION_SYNONYMS = {\n",
    "    \"get\": [\"take\", \"grab\", \"pick up\", \"Take\", \"Grab\", \"Pick up\"],\n",
    "    \"Get\": [\"Take\", \"Grab\", \"Pick up\", \"take\", \"grab\", \"pick up\"],\n",
    "    \"put\": [\"place\", \"drop\"],\n",
    "    \"Put\": [\"Place\", \"Drop\"],\n",
    "    \"drop\": [\"leave\", \"release\"],\n",
    "    \"Drop\": [\"Leave\", \"Release\"],\n",
    "    \"read\": [\"look at\", \"examine\"],\n",
    "    \"Read\": [\"Look at\", \"Examine\"],\n",
    "    \"kill\": [\"attack\", \"strike\"],\n",
    "    \"Kill\": [\"Attack\", \"Strike\"],\n",
    "    \"light\": [\"turn on\"],\n",
    "    \"Light\": [\"Turn on\"],\n",
    "    \"douse\": [\"extinguish\", \"put out\"],\n",
    "    \"Douse\": [\"Extinguish\", \"Put out\"],\n",
    "}\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a reward model trained to evaluate the quality of actions taken in the game Zork.\\n\"\n",
    "    \"You are given the player's current location, their inventory, and the action they just performed.\\n\"\n",
    "    \"Your task is to score how beneficial the action is on a scale from 0 to 1, where:\\n\"\n",
    "    \"- 0 means the action is useless or redundant\\n\"\n",
    "    \"- 1 means the action is extremely valuable for game progression\\n\\n\"\n",
    "    \"You should reward actions that:\\n\"\n",
    "    \"- Collect or use key items (e.g., lamp, keys)\\n\"\n",
    "    \"- Explore new areas\\n\"\n",
    "    \"- Solve puzzles (e.g., moving rug, praying at mirror)\\n\"\n",
    "    \"- Defeat enemies\\n\"\n",
    "    \"- Store treasures\\n\"\n",
    "    \"- Progress the story\\n\\n\"\n",
    "    \"You should penalty actions that:\\n\"\n",
    "    \"- Useless direction move and repeat\\n\"\n",
    ")\n",
    "\n",
    "class ZorkRMHistoryDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer=None, max_history=3, max_length=1024):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_history = max_history\n",
    "        self.max_length = max_length\n",
    "        self.data = self.build_from_walkthrough(path)\n",
    "\n",
    "    def build_from_walkthrough(self, path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "        raw_rewards = []\n",
    "        for line in lines:\n",
    "            r = line.get(\"reward\", 0)\n",
    "            raw_rewards.append(r)\n",
    "\n",
    "        min_reward = min(raw_rewards)\n",
    "        max_reward = max(raw_rewards)\n",
    "        reward_range = max_reward - min_reward if max_reward > min_reward else 1\n",
    "        print(max_reward)\n",
    "        samples = []\n",
    "        for i in range(1, len(lines)-1):\n",
    "            history = lines[max(0, i - self.max_history):i]\n",
    "            location = lines[i].get(\"location\", \"Unknown\")\n",
    "            inventory = lines[i].get(\"inventory\", [])\n",
    "            action = lines[i].get(\"gold_action\", \"\")\n",
    "            reward = lines[i].get(\"reward\", 0)\n",
    "\n",
    "            normalized_reward = (reward - min_reward) / reward_range\n",
    "\n",
    "            sample = {\n",
    "                \"history\": history,\n",
    "                \"location\": location,\n",
    "                \"inventory\": inventory,\n",
    "                \"gold_action\": action,\n",
    "                \"reward\": normalized_reward\n",
    "            }\n",
    "            samples.append(sample)\n",
    "            words = action.split()\n",
    "            if words:\n",
    "                verb = words[0]\n",
    "                if verb in ACTION_SYNONYMS:\n",
    "                    synonyms = ACTION_SYNONYMS[verb]\n",
    "                    synonym = random.choice(synonyms)\n",
    "                    aug_action = action.replace(verb, synonym, 1)\n",
    "                    aug_sample = {\n",
    "                        \"history\": history,\n",
    "                        \"location\": location,\n",
    "                        \"inventory\": inventory,\n",
    "                        \"gold_action\": aug_action,\n",
    "                        \"reward\": normalized_reward\n",
    "                    }\n",
    "                    samples.append(aug_sample)\n",
    "        return samples\n",
    "\n",
    "\n",
    "    def build_prompt(self, item):\n",
    "        prompt = SYSTEM_PROMPT\n",
    "\n",
    "        if item.get(\"history\"):\n",
    "            prompt += \"--- Previous Actions & Observations ---\\n\"\n",
    "            for step in item[\"history\"]:\n",
    "                prompt += f\"location:{step['location'].strip()} \\n inventory:{step['inventory']} \\n>action:{step['gold_action'].strip()}\\n\\n\"\n",
    "            prompt += \"\\n\"\n",
    "\n",
    "        prompt += \"--- Current Observation ---\\n\"\n",
    "        prompt += f\"Location: {item['location']}\\n\"\n",
    "        prompt += f\"Inventory: {item['inventory']}\\n\"\n",
    "        prompt += f\"Action: {item['gold_action']}\\n\\n\"\n",
    "        prompt += \"Score this action from 0 to 1:\\nAnswer:\"\n",
    "        return prompt\n",
    "\n",
    "    def to_jsonl(self, output_path):\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for item in self.data:\n",
    "                context = self.build_prompt(item)\n",
    "                target = item[\"reward\"]\n",
    "                record = {\n",
    "                    \"context\": context,\n",
    "                    \"target\": str(target)\n",
    "                }\n",
    "                f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "dataset = ZorkRMHistoryDataset('raw/zork1_walkthrough_reward_relabel.jsonl')\n",
    "dataset.to_jsonl('raw/zork1_rm_lora_dataset_penalty_argumented.jsonl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zork-Ⅱ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from jericho import *\n",
    "\n",
    "env = FrotzEnv(\"../../../z-machine-games-master/jericho-game-suite/zork2.z5\")\n",
    "initial_observation, info = env.reset()\n",
    "walkthrough = env.get_walkthrough()\n",
    "\n",
    "with open('raw/zork2_z5_walkthrough.jsonl', 'w', encoding='utf-8') as f:\n",
    "    initial_data = {\n",
    "        \"observation\": initial_observation,\n",
    "        \"inventory\": env.get_inventory(),\n",
    "        \"candidates\": env.get_valid_actions(),\n",
    "        \"gold_action\": walkthrough[0].lower()\n",
    "    }\n",
    "    f.write(json.dumps(initial_data) + '\\n')\n",
    "\n",
    "    for step, act in enumerate(walkthrough):\n",
    "        return_ = env.step(act)\n",
    "        if step + 1 >= len(walkthrough):\n",
    "            break  # 避免越界\n",
    "        data = {\n",
    "            \"observation\": return_[0],\n",
    "            \"inventory\": [item.name for item in env.get_inventory()],\n",
    "            \"candidates\": env.get_valid_actions(),\n",
    "            \"gold_action\": walkthrough[step + 1].lower()\n",
    "        }\n",
    "        f.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are playing the interactive fiction game Zork.\\n\"\n",
    "    \"Your goal is to explore the world, collect treasures, solve puzzles, and maximize your score.\\n\"\n",
    "    \"You interact with the world by typing commands like \\\"go north\\\", \\\"open door\\\", \\\"take lamp\\\", etc.\\n\"\n",
    "    \"You see the world through textual descriptions (observations), and your inventory tells you what you're carrying.\\n\"\n",
    "    \"At each step, you will be shown some candidate actions for reference.\\n\"\n",
    "    \"You can either choose one of them, or generate your own appropriate action to proceed.\\n\\n\"\n",
    ")\n",
    "\n",
    "class ZorkSFTDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer=None, max_history=3, max_length=1024):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_history = max_history\n",
    "        self.max_length = max_length\n",
    "        self.data = self.build_from_walkthrough(path)\n",
    "\n",
    "    def build_from_walkthrough(self, path):\n",
    "        with open(path, \"r\") as f:\n",
    "            lines = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "        samples = []\n",
    "        for i in range(1, len(lines)-1):\n",
    "            history = lines[max(0, i - self.max_history):i]\n",
    "            sample = {\n",
    "                \"history\": history,\n",
    "                \"observation\": lines[i][\"observation\"],\n",
    "                \"inventory\": lines[i][\"inventory\"],\n",
    "                \"candidates\": lines[i][\"candidates\"], \n",
    "                \"gold_action\": lines[i][\"gold_action\"]\n",
    "            }\n",
    "            samples.append(sample)\n",
    "        return samples\n",
    "\n",
    "    def build_prompt(self, item):\n",
    "        prompt = SYSTEM_PROMPT\n",
    "\n",
    "        if item.get(\"history\"):\n",
    "            prompt += \"--- Previous Actions & Observations ---\\n\"\n",
    "            for step in item[\"history\"]:\n",
    "                prompt += f\"{step['observation'].strip()} \\n>{step['gold_action'].strip()}\\n\"\n",
    "            prompt += \"\\n\"\n",
    "\n",
    "        prompt += \"--- Current Observation ---\\n\"\n",
    "        prompt += f\"Observation: {item['observation']}\\n\"\n",
    "        prompt += f\"Inventory: {item['inventory']}\\n\"\n",
    "\n",
    "        if item[\"candidates\"]:\n",
    "            prompt += \"Choices:\\n\"\n",
    "            for i, choice in enumerate(item[\"candidates\"], 1):\n",
    "                prompt += f\"({i}) {choice}\\n\"\n",
    "        prompt += \"\\nWhat should you do next?\\nAnswer:\"\n",
    "        return prompt\n",
    "\n",
    "    def to_jsonl(self, output_path):\n",
    "        with open(output_path, \"w\") as f:\n",
    "            for item in self.data:\n",
    "                context = self.build_prompt(item)\n",
    "                target = item[\"gold_action\"]\n",
    "                record = {\n",
    "                    \"context\": context,\n",
    "                    \"target\": target\n",
    "                }\n",
    "                f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "dataset = ZorkSFTDataset('raw/zork2_z5_walkthrough.jsonl')\n",
    "dataset.to_jsonl('raw/zork2_wt_lora.jsonl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "\n",
    "def preprocess(tokenizer, config, example, max_seq_length):\n",
    "    prompt = example[\"context\"]\n",
    "    target = example[\"target\"]\n",
    "    prompt_ids = tokenizer.encode(prompt, max_length=max_seq_length, truncation=True)\n",
    "    target_ids = tokenizer.encode(\n",
    "        target,\n",
    "        max_length=max_seq_length,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False)\n",
    "    input_ids = prompt_ids + target_ids + [config.eos_token_id]\n",
    "    return {\"input_ids\": input_ids, \"seq_len\": len(prompt_ids)}\n",
    "\n",
    "\n",
    "def read_jsonl(model_name, path, max_seq_length, skip_overlength=False):\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(f\"{model_name}\", trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    config = transformers.AutoConfig.from_pretrained(\n",
    "        f\"/data3/whr/zhk/huggingface/{model_name}\", trust_remote_code=True, device_map='auto')\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            example = json.loads(line)\n",
    "            feature = preprocess(tokenizer, config, example, max_seq_length)\n",
    "            if skip_overlength and len(feature[\"input_ids\"]) > max_seq_length:\n",
    "                continue\n",
    "            feature[\"input_ids\"] = feature[\"input_ids\"][:max_seq_length]\n",
    "            yield feature\n",
    "\n",
    "\n",
    "\n",
    "jsonl_path = \"raw/zork2_wt_lora.jsonl\"\n",
    "save_path = \"processed/\"\n",
    "max_seq_length = 1024\n",
    "model_name = \"qwen-2.5-0.5B-instruct\"\n",
    "skip_overlength = False\n",
    "\n",
    "print(\"#> Tokenizing dataset...\")\n",
    "print(\"#> Input path: {}\".format(jsonl_path))\n",
    "print(\"#> Output path: {}\".format(save_path))\n",
    "print(\"#> Max sequence length: {}\".format(max_seq_length))\n",
    "print(\"#> Skip overlength: {}\".format(skip_overlength))\n",
    "\n",
    "\n",
    "\n",
    "dataset = datasets.Dataset.from_generator(\n",
    "    lambda: read_jsonl(model_name, jsonl_path, max_seq_length, skip_overlength)\n",
    ")\n",
    "save_path = f'processed/{model_name}_z2'\n",
    "dataset.save_to_disk(save_path)\n",
    "\n",
    "print(\"#> Tokenization finished!\", \"Total examples:\", len(dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zst_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
